{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_config = '''out_dir: {out_dir}\n",
    "metric_best: accuracy\n",
    "device: 'cuda:0'\n",
    "wandb:\n",
    "  use: True\n",
    "  project: {wandb_proj_name}\n",
    "  entity: <WANDB_USERNAME>\n",
    "dataset:\n",
    "  format: PyG\n",
    "  name: {ds}\n",
    "  dir: {ds_download_dir}\n",
    "  task: node\n",
    "  task_type: classification_multi\n",
    "  transductive: True\n",
    "  split_mode: standard\n",
    "  node_encoder: True\n",
    "  node_encoder_name: LapPE\n",
    "  node_encoder_bn: False\n",
    "  edge_encoder: False\n",
    "  edge_encoder_name: DummyEdge\n",
    "  edge_encoder_bn: False\n",
    "posenc_LapPE:\n",
    "  enable: True\n",
    "  eigen:\n",
    "    laplacian_norm: none\n",
    "    eigvec_norm: L2\n",
    "    max_freqs: 4\n",
    "  model: DeepSet\n",
    "  dim_pe: 4\n",
    "  layers: 2\n",
    "  n_heads: 4  # Only used when `posenc.model: Transformer`\n",
    "  raw_norm_type: none\n",
    "train:\n",
    "  mode: custom\n",
    "  sampler: full_batch\n",
    "  eval_period: 1\n",
    "  enable_ckpt: False\n",
    "model:\n",
    "  type: GPSModel\n",
    "  loss_fun: cross_entropy\n",
    "  edge_decoding: dot\n",
    "gt:\n",
    "  layer_type: GCN+Transformer\n",
    "  layers: {num_layers}\n",
    "  n_heads: {num_heads}\n",
    "  dim_hidden: {dim_hidden}  # `gt.dim_hidden` must match `gnn.dim_inner`\n",
    "  dropout: {dropout}\n",
    "  attn_dropout: {attn_dropout}\n",
    "  layer_norm: False\n",
    "  batch_norm: False\n",
    "gnn:\n",
    "  head: node\n",
    "  layers_pre_mp: 0\n",
    "  layers_post_mp: 1\n",
    "  dim_inner: {dim_hidden}  # `gt.dim_hidden` must match `gnn.dim_inner`\n",
    "  batchnorm: True\n",
    "  act: gelu\n",
    "  dropout: {dropout}\n",
    "  agg: mean\n",
    "  normalize_adj: False\n",
    "optim:\n",
    "  clip_grad_norm: True\n",
    "  optimizer: adamW\n",
    "  weight_decay: 1e-10\n",
    "  base_lr: 0.001\n",
    "  max_epoch: 1000\n",
    "  scheduler: reduce_on_plateau\n",
    "  num_warmup_epochs: 0\n",
    "  early_stopping_patience: 30\n",
    "  reduce_factor: 0.5\n",
    "  schedule_patience: 15\n",
    "share:\n",
    "  dim_out: {num_classes}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = {\n",
    "    'Cora': 7,\n",
    "    'CiteSeer': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure to add your correct paths!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in ['Cora', 'CiteSeer']:\n",
    "    num_classes = NUM_CLASSES[ds]\n",
    "\n",
    "    for seed in [0]:\n",
    "        for dim_hidden in [128]:\n",
    "            for num_layers in [4]:\n",
    "                for num_heads in [4]:\n",
    "                    for attn_dropout in [0.1]:\n",
    "                        for dropout in [0.0]:\n",
    "                            CONFIG_PATH = f'<YOUR_PATH>/training_configs_{ds}'\n",
    "                            SCRIPT_PATH = f'<YOUR_PATH>/training_scripts_{ds}'\n",
    "\n",
    "                            Path(CONFIG_PATH).mkdir(exist_ok=True, parents=True)\n",
    "                            Path(SCRIPT_PATH).mkdir(exist_ok=True, parents=True)\n",
    "                        \n",
    "                            dl_dir = f'<DL_PATH>/{ds}'\n",
    "                            out_dir = f'<OUT_PATH>/{ds}/{seed}/{dim_hidden}/{num_layers}/{num_heads}/{attn_dropout}/{dropout}'\n",
    "                            wandb_proj_name = f'<WANDB_PROJ>'\n",
    "\n",
    "                            conf = template_config.format(\n",
    "                                ds=ds, seed=seed, out_dir=out_dir, dim_hidden=dim_hidden, num_layers=num_layers, num_heads=num_heads,\n",
    "                                ds_download_dir=dl_dir, wandb_proj_name=wandb_proj_name, num_classes=num_classes, attn_dropout=attn_dropout,\n",
    "                                dropout=dropout\n",
    "                            )\n",
    "                            with open(os.path.join(CONFIG_PATH, f'{ds}_{seed}_{dim_hidden}_{num_layers}_{num_heads}_{attn_dropout}_{dropout}.yaml'), 'w') as f:\n",
    "                                f.write(conf)\n",
    "\n",
    "                            script = f'python <YOUR_PATH>/graphgps_node/main.py --cfg {CONFIG_PATH}/{ds}_{seed}_{dim_hidden}_{num_layers}_{num_heads}_{attn_dropout}_{dropout}.yaml'\n",
    "                            with open(f'{SCRIPT_PATH}/{ds}_{seed}_{dim_hidden}_{num_layers}_{num_heads}_{attn_dropout}_{dropout}.sh', 'w') as f:\n",
    "                                f.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
